{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa43476-cfa5-4bf4-89f0-b7de4f7280ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To avoid warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331ad01-91d2-4672-b247-acaa5aa63fbe",
   "metadata": {},
   "source": [
    "## To apply land-sea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec171b-6f08-4ab3-825b-078cc5e088d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_sea_mask = xr.open_dataset(\"/discover/nobackup/projects/gmao/advda/sakella/future_sst_fraci/gen_daily_clim_data/data/geos_fp_bcs_land_sea_mask.nc\")\n",
    "my_mask = land_sea_mask.land_mask.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb192806-5620-42f3-a51a-80158daa1a69",
   "metadata": {},
   "source": [
    "### Local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655bb43a-27b3-4472-828a-bfb6457d9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names: real data and daily climatology\n",
    "def get_files_names(dates, data_path, file_pref, clim=False, file_suff=\".nc\"):\n",
    "   files_to_read = []\n",
    "   for idate in dates:\n",
    "\n",
    "     if (clim==False): # real data\n",
    "       ff = data_path + str(idate.year) + \"/\" +\\\n",
    "            file_pref + str(idate.year) + str(idate.month).zfill(2) + str(idate.day).zfill(2) +\\\n",
    "            file_suff\n",
    "     else:\n",
    "       ff = data_path + \"/\"+\\\n",
    "            file_pref + \"0001\" + str(idate.month).zfill(2) + str(idate.day).zfill(2) +\\\n",
    "            file_suff\n",
    "\n",
    "     #print(ff)\n",
    "     files_to_read.append(ff)\n",
    "   return files_to_read\n",
    "\n",
    "# We need to mask out land\n",
    "def apply_mask( input_field, mask, tol=0.1):\n",
    "  output_field = np.copy( input_field)\n",
    "  output_field [mask<tol] = np.nan\n",
    "  return output_field\n",
    "\n",
    "# mask land\n",
    "def mask_array(ds, iTime, vName='SST', mask=my_mask):\n",
    "    arr = ds[vName].isel(time=iTime).values\n",
    "    masked_arr=apply_mask(arr, mask)\n",
    "    return masked_arr\n",
    "\n",
    "# to write forecast stats\n",
    "def write_stats(vName, var):\n",
    "    f1 = vName + \"_{}_{}.csv\".format(exp_dates[0].strftime('%Y%m%d'), exp_dates[-1].strftime('%Y%m%d'))\n",
    "    print(\"Writing out: \", f1)\n",
    "    np.savetxt(f1, (var), delimiter=\",\", fmt='%1.4f')\n",
    "    print(\"Done!\")\n",
    "\n",
    "# Unweighted mean and std dev\n",
    "def unWeighted_mean_sdev(arr):\n",
    "    mean_arr = np.nanmean(arr.flatten(), dtype=np.float64)\n",
    "    sdev_arr =  np.nanstd(arr.flatten(), dtype=np.float64)\n",
    "    return mean_arr, sdev_arr\n",
    "\n",
    "def get_first_day(ds, classifacation='TS'):\n",
    "    # first time it became Tropical Storm 'TS'\n",
    "    id=np.where(ds.type==classifacation)[0][0]\n",
    "    date0=ds.time[id]\n",
    "    #print(\"{}/{}/{}\".format(date0.year,str(date0.month).zfill(2),str(date0.day).zfill(2)))\n",
    "    return date0\n",
    "\n",
    "def make_data_arr(arr, mask=land_sea_mask):\n",
    "    da = xr.DataArray(data=arr, \n",
    "                      coords={'lat': mask.lat,'lon': mask.lon}, \n",
    "                      dims=[\"lat\", \"lon\"],\n",
    "                      attrs=dict(description=\"See https://github.com/sanAkel/future_sst_fraci/blob/main/to_gen_new_files/SST_under_TC.ipynb\"))\n",
    "    return da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc5fb3-5534-4f2b-a469-f3691ce84047",
   "metadata": {},
   "source": [
    "### Different methods to predict future BCs, see below for mathematical details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999715e-8007-4030-862d-b3b539ac7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_bc(method, id, bc0, clim_bc, anomaly0):\n",
    "    \n",
    "    predicted_bc = np.zeros_like(bc0) # init to be safe!\n",
    "    \n",
    "    if method == \"persist\":\n",
    "        predicted_bc = bc0 # persistence throughout the forecast\n",
    "    elif method == \"persist_init_anom\":\n",
    "        if (id==0):\n",
    "            predicted_bc = bc0 # forecast start day\n",
    "        else:\n",
    "            predicted_bc = clim_bc + anomaly0\n",
    "    elif method == \"test3\":\n",
    "        if (id==0):\n",
    "            predicted_bc = bc0 # forecast start day\n",
    "        else:\n",
    "            predicted_bc = clim_bc - anomaly0\n",
    "    elif method == \"test4\":\n",
    "        if (id==0):\n",
    "            predicted_bc = bc0 # forecast start day\n",
    "        else:\n",
    "            predicted_bc = bc0 + anomaly0       \n",
    "    else:\n",
    "        print(\"Uknown method: {} for creating future BCs.\".format(method))\n",
    "        \n",
    "    return predicted_bc    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afed568-26ba-4ffe-abdc-ee4e8410a5f0",
   "metadata": {},
   "source": [
    "## Read pre-processed storm info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707431a7-0d8a-41b3-93be-63465a0c7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "tc_name = 'franklin' \n",
    "ds_tc= xr.open_dataset(tc_name+ str(year)+'.nc')\n",
    "#date_TS = get_first_day(ds_tc)\n",
    "#\n",
    "#print(\"\\nHurricane:\\t{} became tropical storm on:\\t{}\".format(tc_name.upper(), date_TS['time'].dt.strftime(\"%Y-%m-%d\").values))\n",
    "\n",
    "start_date = str(ds_tc['time'][0].dt.strftime(\"%Y-%m-%d\").values)\n",
    "end_date = str(ds_tc['time'][-1].dt.strftime(\"%Y-%m-%d\").values)\n",
    "print(\"\\nHurricane:\\t{} originated on:\\t{},\\t dissipated on:\\t{}.\".format(tc_name.upper(), start_date, end_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedee352-ec1a-4a71-830f-db8b48795dfa",
   "metadata": {},
   "source": [
    "## See `SST_ideas` notebook reg inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c03b15-19fd-4bd5-9c12-2747d3207c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_nDays, nfcst = [10, 13] # ?? forecasts following tropical storm categorization.\n",
    "\n",
    "start_date, end_date = [start_date, end_date] # end_date must fit above.\n",
    "\n",
    "data_path_real = \"/discover/nobackup/projects/gmao/advda/sakella/future_sst_fraci/GMAO_OPS_bin_data/data/\"\n",
    "data_path_clim = \"/discover/nobackup/projects/gmao/advda/sakella/future_sst_fraci/data/ncFiles/\"\n",
    "\n",
    "file_pref_real, file_suff = [\"sst_ice_\", \".nc\"]\n",
    "file_pref_clim, file_suff = [\"daily_clim_mean_sst_fraci_\", \".nc\"]\n",
    "\n",
    "# Select _forecast_ method\n",
    "method = \"persist\" \n",
    "#method = \"persist_init_anom\"\n",
    "#method = \"test3\"\n",
    "#method = \"test4\"\n",
    "\n",
    "vName = 'SST' # always SST, ice concentration is irrelevant in TC context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bd94c7-a4f0-4519-a916-e4d5da3593b3",
   "metadata": {},
   "source": [
    "## Dates of forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1b4c9-d3a2-4270-a198-a14578391ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One forecast per day, since this is daily BCs.\n",
    "exp_dates  = pd.date_range(str(start_date), end_date, freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff9363-afd4-4c13-bcf4-b0d766142f71",
   "metadata": {},
   "source": [
    "## Initialize arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf096887-535f-4317-9281-45b7290264e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With respect to real data -- remember, we _test_ in **hindcast** mode, so we know the _truth_.\n",
    "error_real = np.zeros((ds_tc.time.shape[0], fcst_nDays, nfcst), dtype=np.float64)\n",
    "\n",
    "# With respect to daily climatology\n",
    "error_clim = np.zeros_like(error_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4c342-1d0e-4aaf-aa60-951c99cb19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ifcst in range(1, nfcst+1): # each forecast\n",
    "\n",
    "  fcst_start_date = exp_dates[0] + pd.DateOffset(days=ifcst-1)\n",
    "  fcst_dates = pd.date_range(start=fcst_start_date, periods=fcst_nDays)\n",
    "  print(\"Forecast [{}] Dates: {}\".format(ifcst,fcst_dates))\n",
    "\n",
    "  files_names_real_data = get_files_names(fcst_dates, data_path_real, file_pref_real)\n",
    "  clim_files_names      = get_files_names(fcst_dates, data_path_clim, file_pref_clim, clim=True)\n",
    "\n",
    "  ds_real = xr.open_mfdataset(files_names_real_data)\n",
    "  ds_clim = xr.open_mfdataset(clim_files_names, concat_dim='time', combine='nested', use_cftime=True)\n",
    "\n",
    "  for id in range(0, fcst_nDays): # over each day of forecast\n",
    "    real_bc = mask_array(ds_real, id); clim_bc = mask_array(ds_clim, id)\n",
    "\n",
    "    # save initial BC (SST/ICE)\n",
    "    if (id==0):\n",
    "      bc0 = real_bc; anom0 = bc0 - clim_bc\n",
    "   \n",
    "    predicted_bc = forecast_bc(method, id, bc0, clim_bc, anom0)\n",
    "       \n",
    "    err_real=make_data_arr(predicted_bc-real_bc) # data array to ease selection along TC track\n",
    "    err_clim=make_data_arr(clim_bc - real_bc)\n",
    "    \n",
    "    error_real[:,id,ifcst-1]=err_real.sel(lat=ds_tc.lat, lon=ds_tc.lon, method='nearest').values\n",
    "    error_clim[:,id,ifcst-1]=err_clim.sel(lat=ds_tc.lat, lon=ds_tc.lon, method='nearest').values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc80cbb-f0c4-4e53-95fb-ab8ffa4a8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56988d7a-8640-4ff3-bbc0-39b0c44b799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifcst=4\n",
    "\n",
    "plt.figure( figsize=(16, 10))\n",
    "\n",
    "for id in range(0, fcst_nDays):\n",
    "    plt.subplot(3,4,id+1)\n",
    "    plt.scatter(ds_tc.lon, ds_tc.lat, s=6, c=error_real[:,id,ifcst].squeeze(), cmap=plt.cm.bwr)\n",
    "    plt.colorbar()\n",
    "    plt.title(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67b114-2107-46db-b977-dddb9c743533",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ffd58-98af-4074-8a52-cc05c7bf82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_real_error = np.zeros((ds_tc.time.shape[0], fcst_nDays), dtype=np.float64)\n",
    "sdev_real_error = np.zeros((ds_tc.time.shape[0], fcst_nDays), dtype=np.float64)\n",
    "\n",
    "for ifcst in range(0,nfcst):\n",
    "    if (ifcst == 0):\n",
    "        mean_real_error = error_real[:,:,ifcst].squeeze()\n",
    "    else:\n",
    "        mean_real_error = mean_real_error + error_real[:,:,ifcst].squeeze()\n",
    "\n",
    "mean_real_error = mean_real_error/fcst_nDays"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Min4.11.0",
   "language": "python",
   "name": "min4.11.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
